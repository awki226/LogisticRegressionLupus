{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#################################### Libraries #######################################\n#%% libraries\nimport os # setting working directory\nimport numpy as np # for generating random embeddings\nimport pandas as pd # importing a csv\nimport re\nimport random\nimport spacy # basic text processing\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import *\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow_addons.metrics import F1Score\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nplt.style.use('ggplot')\nfrom statistics import harmonic_mean\nimport pickle\nfrom tensorflow.keras.layers import Embedding, LSTM, Conv1D, Bidirectional, Dense, Concatenate, GlobalMaxPooling1D, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-12T22:17:46.316442Z","iopub.execute_input":"2021-12-12T22:17:46.316777Z","iopub.status.idle":"2021-12-12T22:17:53.46846Z","shell.execute_reply.started":"2021-12-12T22:17:46.316695Z","shell.execute_reply":"2021-12-12T22:17:53.466956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sets working directory\nos.chdir('/kaggle/input/largedatasets2')\n\n# sets pseudorandom seeds\nrandom.seed(0)\nnp.random.seed(0)\ntf.random.set_seed(0)    \n\n### TPU usage\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:17:53.470908Z","iopub.execute_input":"2021-12-12T22:17:53.471971Z","iopub.status.idle":"2021-12-12T22:17:59.794323Z","shell.execute_reply.started":"2021-12-12T22:17:53.471893Z","shell.execute_reply":"2021-12-12T22:17:59.793542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('202011_202110_train_dataset_3.csv')\n\nmax_len = 0\nfor i in train['text'].values:\n    if max_len < len(i):\n        max_len = len(i)\n\n#train_testsplit\nx_train, x_valid, y_train, y_valid = train_test_split(train['text'].values, train['popular'].values, test_size = 0.2, random_state = 0)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:17:59.795381Z","iopub.execute_input":"2021-12-12T22:17:59.79614Z","iopub.status.idle":"2021-12-12T22:18:00.372092Z","shell.execute_reply.started":"2021-12-12T22:17:59.796092Z","shell.execute_reply":"2021-12-12T22:18:00.370551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tokenize the sentences\ntokenizer = Tokenizer()\n\n#preparing vocabulary\ntokenizer.fit_on_texts(list(x_train))\nmax_l = 0\nfor i in x_train:\n    if max_l < len(i):\n        max_l = len(i)\n        \n#converts text into integer sequences\nx_train_seq  = tokenizer.texts_to_sequences(x_train) \nx_valid_seq = tokenizer.texts_to_sequences(x_valid)\n\n#padding to prepare sequences of same length\nx_train_seq  = pad_sequences(x_train_seq)\nx_valid_seq = pad_sequences(x_valid_seq)\n\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:18:00.374343Z","iopub.execute_input":"2021-12-12T22:18:00.374934Z","iopub.status.idle":"2021-12-12T22:18:05.533553Z","shell.execute_reply.started":"2021-12-12T22:18:00.374888Z","shell.execute_reply":"2021-12-12T22:18:05.532637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('202011_202110_test_dataset_3.csv')\nt = Tokenizer()\nx_test = test['text'].values\nt.fit_on_texts(list(x_test))\n\nx_test_seq = t.texts_to_sequences(x_test)\nx_test_seq  = pad_sequences(x_test_seq)\ny_test = test['popular'].values\n#x_test = t.texts_to_sequences(test['selftext'].values) \n#y_test = t.texts_to_sequences(test['class'].values)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:18:05.53485Z","iopub.execute_input":"2021-12-12T22:18:05.535089Z","iopub.status.idle":"2021-12-12T22:18:07.02593Z","shell.execute_reply.started":"2021-12-12T22:18:05.535061Z","shell.execute_reply":"2021-12-12T22:18:07.024899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle/input/glove6b')\nembeddings_index = dict()\nf = open('glove.6B.300d.txt')\n\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\n\nf.close()\nprint('Loaded %s word vectors.' % len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:18:07.027244Z","iopub.execute_input":"2021-12-12T22:18:07.027491Z","iopub.status.idle":"2021-12-12T22:19:01.264102Z","shell.execute_reply.started":"2021-12-12T22:18:07.027463Z","shell.execute_reply":"2021-12-12T22:19:01.260365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########################## custom CNN with multiple filter window sizes ##############################\nclass Conv1D_multiple_filters(keras.layers.Layer):\n    # intializes class attributes\n    def __init__(self, filter_size_list, filter_num_list, activation, pooling_fun):\n        super().__init__()\n         \n        self.num_window_sizes = len(filter_size_list)\n        self.convolutions_list = [Conv1D(filter_num_list[i],\n                                   filter_size_list[i],\n                                   activation = activation)\n                             for i in range(self.num_window_sizes)\n                             ]\n        self.pooling_fun = pooling_fun()\n        self.concat = Concatenate()\n        \n    def call(self, x):\n        # runs n-grams through convolutions with activation functions\n        x = [self.convolutions_list[i](x) for i in range(self.num_window_sizes)]\n        \n        # pooling\n        x = [self.pooling_fun(x[i]) for i in range(self.num_window_sizes)]\n                \n        # concatenates results from different filter sizes.  If only bigrams are used, then there is not concatentation to be done.\n        if len(x) == 1:\n            x = x[0] # list of 1 tensor -> tensor\n        elif len(x) > 1:\n            x = self.concat(x) # concatentates list of >1 tensors to one tensor.\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:19:01.265425Z","iopub.execute_input":"2021-12-12T22:19:01.265674Z","iopub.status.idle":"2021-12-12T22:19:01.278211Z","shell.execute_reply.started":"2021-12-12T22:19:01.265646Z","shell.execute_reply":"2021-12-12T22:19:01.276757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% F-score metric\nclass F1(tf.keras.metrics.Metric):\n    # initializing class object\n    def __init__(self, name='F1', **kwargs):\n        super(F1, self).__init__(name=name, **kwargs)\n        \n        # intializes # TP's, FP's, and FN's to 0\n        self.TP = self.add_weight(name='TP', initializer='zeros')\n        self.FP = self.add_weight(name='FP', initializer='zeros')\n        self.FN = self.add_weight(name='FN', initializer='zeros')\n\n    # accumulates TP's, FP's, and FN's over batches in epoch\n    def update_state(self, y_true, y_pred, sample_weight = None):\n        \n        # converts probability score to boolean\n        y_pred = tf.where(y_pred > 0.5, True, False)\n\n        # ensures quantities are boolean\n        y_true = tf.cast(y_true, tf.bool)\n        y_pred = tf.cast(y_pred, tf.bool)\n        \n        # calculates # TP's, FP's, FN's in batch\n        TP_tensor = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n        TP_tensor = tf.cast(TP_tensor, self.dtype)\n        TP = tf.reduce_sum(TP_tensor)\n        \n        FP_tensor = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True))\n        FP_tensor = tf.cast(FP_tensor, self.dtype)\n        FP = tf.reduce_sum(FP_tensor)\n        \n        FN_tensor = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, False))\n        FN_tensor = tf.cast(FN_tensor, self.dtype)\n        FN = tf.reduce_sum(FN_tensor)\n        \n        # adds TP's, FP's and FN's to those of previous batches in epoch\n        self.TP.assign_add(TP)\n        self.FP.assign_add(FP)\n        self.FN.assign_add(FN)\n    \n    # calculates F-score\n    def result(self):\n        \n        precision = tf.math.divide(self.TP, tf.math.add(self.TP, self.FP))\n        recall = tf.math.divide(self.TP, tf.math.add(self.TP, self.FN))\n        \n        numerator = 2 * tf.math.multiply(precision, recall)\n        denominator = tf.math.add(precision, recall)\n        \n        F1 = tf.math.divide(numerator, denominator)\n        \n        return F1\n    \n    # resets TP's, FP's, and FN's to 0 at the end of epoch\n    def reset_state(self):\n        self.TP.assign(0)\n        self.FP.assign(0)\n        self.FN.assign(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:19:01.280133Z","iopub.execute_input":"2021-12-12T22:19:01.280488Z","iopub.status.idle":"2021-12-12T22:19:01.302548Z","shell.execute_reply.started":"2021-12-12T22:19:01.280445Z","shell.execute_reply":"2021-12-12T22:19:01.301174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############################## tracking model fitting ####################################\n# plots validation loss\ndef plot_loss(history):\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(val_loss) + 1)\n\n    plt.plot(epochs, val_loss, 'b')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation Loss\")\n    plt.legend()\n\ndef plot_F1(history):\n    val_f1 = history.history['val_F1']\n    epochs = range(1, len(val_f1) + 1)\n\n    plt.plot(epochs, val_f1, 'b')\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Validation F1\")\n    plt.legend()\n\ndef plot_acc(history):\n    plt.plot(history.history['precision'])\n    plt.plot(history.history['val_precision'])\n    plt.title('Model Precision')\n    plt.ylabel('precision')\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'val'], loc ='upper left')\n    \ndef plot_loss(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Training/Validation loss')\n    plt.ylabel('loss')\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'val'], loc ='upper left')\n    \ndef plot_f1(history):\n    plt.plot(history.history['F1'])\n    plt.plot(history.history['val_F1'])\n    plt.title('Model F scores')\n    plt.ylabel('F scores')\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'val'], loc ='upper left')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:19:01.306921Z","iopub.execute_input":"2021-12-12T22:19:01.307174Z","iopub.status.idle":"2021-12-12T22:19:01.32424Z","shell.execute_reply.started":"2021-12-12T22:19:01.307146Z","shell.execute_reply":"2021-12-12T22:19:01.32282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########################### Modeling choices ##############################\nembedding_matrix = np.zeros((vocab_size, 300))\nnum_embed = embedding_matrix.shape[0]\ndim_embed = embedding_matrix.shape[1]\n\nfor word, i in tokenizer.word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n    \n# CNN hyperparameter choices -\nnum_filters = 1600 \nmax_ngram = 5 \n\n# mini-batch size (\nbatch_size = 512\nnum_epochs = 300\n\n# dropout \nprob_dropout_input = 0.6\nprob_dropout_after_NN = 0.6\nprob_dropout_rnn = 0.55\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:52:19.036419Z","iopub.execute_input":"2021-12-12T22:52:19.037542Z","iopub.status.idle":"2021-12-12T22:52:19.147383Z","shell.execute_reply.started":"2021-12-12T22:52:19.03748Z","shell.execute_reply":"2021-12-12T22:52:19.146014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##################################### model definition #############################################\n# splits number of filters evenly into filter sizes, and if it doesn't divide evenly, adds one filter to smaller filter sizes until none left\nfilter_size_list = list(range(2, max_ngram + 1))\nfilter_num_list = [num_filters//(max_ngram - 1)] * (max_ngram - 1)\nremainder = num_filters % (max_ngram - 1)\nfor i in range(remainder):\n    filter_num_list[i] += 1\nfrom tensorflow.keras import regularizers\n# sets pseudorandom seeds\nrandom.seed(1)\nnp.random.seed(1)\ntf.random.set_seed(1)\n\nwith tpu_strategy.scope():\n\n    model = Sequential()\n    \n    # using the Sequential module\n    model.add(Embedding(num_embed, dim_embed, \n                               weights=[embedding_matrix], \n                               input_length = max_l, \n                               trainable = False))\n\n    # dropout\n    model.add(Dropout(prob_dropout_input))\n\n    ### adds CNN \n    model.add(Conv1D_multiple_filters(filter_size_list, filter_num_list, activation = 'relu', pooling_fun = GlobalMaxPooling1D))\n    \n    # dropout\n    model.add(Dropout(prob_dropout_after_NN))\n   \n\n    \n\n    #adds a MLP(1) layer\n    model.add(Dense(1, activation = 'sigmoid',kernel_regularizer=regularizers.l2(0.01)))\n    \n\n    # chooses loss function, optimizer, and evaluation metrics\n    fscore = F1()\n    model.compile(optimizer = 'adam',\n                  loss = 'binary_crossentropy',\n                  metrics = ['Precision', 'Recall', fscore])\n    # prints model structure summary (just for user)\n    model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:52:22.89052Z","iopub.execute_input":"2021-12-12T22:52:22.89177Z","iopub.status.idle":"2021-12-12T22:52:23.87436Z","shell.execute_reply.started":"2021-12-12T22:52:22.891721Z","shell.execute_reply":"2021-12-12T22:52:23.873194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################ model fitting ###############################\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_F1',\n                                                  mode = 'max',\n                                                  patience = 15,\n                                                  restore_best_weights = True)\npop_weight = {0:1.0, 1:2.47}\n\nhistory = model.fit(x_train_seq, y_train,\n                    epochs = num_epochs,\n                    verbose = 1, # change to 0 if you don't want to print intermediate results during training\n                    validation_data = (x_valid_seq,y_valid),\n                    batch_size = batch_size,\n                    validation_batch_size = len(y_valid),\n                    callbacks = [early_stopping], class_weight = pop_weight)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:52:26.560918Z","iopub.execute_input":"2021-12-12T22:52:26.561271Z","iopub.status.idle":"2021-12-12T22:54:03.017745Z","shell.execute_reply.started":"2021-12-12T22:52:26.561239Z","shell.execute_reply":"2021-12-12T22:54:03.016771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###################### Performance #############################\n# prediction \ny_pred = np.round(model.predict(x_test_seq)).flatten()\n\n# performance measures\nprecision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average = 'binary')\n\n# printing\nprint('precision : ', precision)\nprint('recall : ', recall)\nprint('F1 : ', f1)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:54:08.5685Z","iopub.execute_input":"2021-12-12T22:54:08.569144Z","iopub.status.idle":"2021-12-12T22:54:19.314489Z","shell.execute_reply.started":"2021-12-12T22:54:08.569092Z","shell.execute_reply":"2021-12-12T22:54:19.313418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#################### Plotting #################\nplot_loss(history)\nplt.show()\nplot_F1(history)\nplt.show()\nplot_acc(history)\nplt.show()\nprint(history.history.keys())\nplot_f1(history)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:54:22.36985Z","iopub.execute_input":"2021-12-12T22:54:22.37025Z","iopub.status.idle":"2021-12-12T22:54:23.222183Z","shell.execute_reply.started":"2021-12-12T22:54:22.370211Z","shell.execute_reply":"2021-12-12T22:54:23.221195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### accessing examples for error analysis\n\n# obtains list of false positive and negative indices\nFPs = [i for i in range(len(y_test)) if y_pred[i] == 1 and y_test[i] == 0]\nFNs = [i for i in range(len(y_test)) if y_pred[i] == 0 and y_test[i] == 1]\n\n# prints out the first several indices\nprint('FP: ', FPs[0:5])\nprint('FN: ', FNs[0:5])\n\n# example index\ni = 2701\n\n# example label\nprint('label: ', y_test[i])\n\n# example predictions\nprint('prediction: ', y_pred[i])\n\n# example text\nprint(test['text'].loc[i])","metadata":{"execution":{"iopub.status.busy":"2021-12-12T22:54:35.298538Z","iopub.execute_input":"2021-12-12T22:54:35.29941Z","iopub.status.idle":"2021-12-12T22:54:35.378Z","shell.execute_reply.started":"2021-12-12T22:54:35.299336Z","shell.execute_reply":"2021-12-12T22:54:35.376954Z"},"trusted":true},"execution_count":null,"outputs":[]}]}